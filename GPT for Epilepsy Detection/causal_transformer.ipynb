{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# HYPERPARAMETERS\n",
    "batch_size = 1  # DON'T ALTER IT!!!\n",
    "eval_batch = 1  # DON'T ALTER IT!!!\n",
    "\n",
    "train_folder = \"/home/dll-1/Desktop/eeg/datasets/dataset_pickle/2019/train\"\n",
    "eval_folder = \"/home/dll-1/Desktop/eeg/datasets/dataset_pickle/2019/eval\"\n",
    "\n",
    "# parameters for data loaders\n",
    "number_of_eeg_channels = 21  # WARNING: If you are altering this, change the \"n_channels\" hyperparam as well below\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Details of model\n",
    "n_embd = 64  # Size of embedding dimension (should be divisible by n_heads evenly)\n",
    "n_head = 2  # Number of heads  \n",
    "n_layer = 1  # No. of transformer blocks                                            (MA'AM HIRA)\n",
    "dropout = 0.01  #                                                                   (MA'AM HIRA)\n",
    "emb_table_size = 10000\n",
    "n_channels = 21 # No. of channels will give to the model                            (MA'AM HIRA)\n",
    "window_size = 9000 # context length for predictions?  --> The bugbearer :)          (MA'AM HIRA)\n",
    "\n",
    "# Training details\n",
    "epochs = 10  #                                                                      (MA'AM HIRA)\n",
    "learning_rate = 1e-3  #                                                             (MA'AM HIRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.data = self.load_data(folder_path)\n",
    "\n",
    "    def load_data(self, folder_path):\n",
    "        data = []\n",
    "        labels = []\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith(\".npz\"):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                data.append(file_path)\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.data[idx]\n",
    "        npz_data = np.load(file_path)\n",
    "        eeg_data = npz_data['array1'][0:number_of_eeg_channels]\n",
    "        label = npz_data['array2']\n",
    "        return torch.tensor(eeg_data, dtype=torch.float32), torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "# Load data from eval and train folders\n",
    "train_dataset = EEGDataset(train_folder)\n",
    "val_dataset = EEGDataset(eval_folder)\n",
    "eval_dataset = EEGDataset(eval_folder)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=eval_batch, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(window_size, window_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "          Input: B, T, C\n",
    "          Output: B, T, C\n",
    "        \"\"\"\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        # print(\"i am in head\", out.device)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        # print(\"i am in multihead\", out.device)\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"i am in FeedFoward\", self.net(x).device)\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        # print(\"I am in block\", x.device)\n",
    "        return x\n",
    "\n",
    "class GPT(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    # Instance Variables\n",
    "    # nn.embedding(no_of_encoding_categories, output_dim_desired_for_each_category)\n",
    "\n",
    "    # Vector Embedding (input: (1xT), Output: (1, T, C))\n",
    "    self.embedder = nn.Linear(window_size, n_embd)\n",
    "    # Positional Embedding (input: (T), Output: (T, C))\n",
    "    self.pos_encoding_table = nn.Embedding(120000, n_embd)\n",
    "\n",
    "    # Encoder Layers\n",
    "    self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "    self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "    self.lm_head = nn.Linear(n_embd, 1)\n",
    "    self.lm_out = nn.Linear(n_channels*window_size, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # x is of shape (B, T)\n",
    "    B, T = x.shape\n",
    "\n",
    "    embedder_inp = x[:, :, None]\n",
    "    embedder_inp = embedder_inp.repeat(1, 1, window_size)\n",
    "    tok_emb = self.embedder(embedder_inp) # (B, T, C)\n",
    "    pos_emb = self.pos_encoding_table(torch.arange(T, device=device)) # (T, C)\n",
    "    x = tok_emb + pos_emb\n",
    "\n",
    "    x = self.blocks(x) # (B, T, C)\n",
    "    x = self.ln_f(x) # (B, T, C)\n",
    "    logits = self.lm_head(x) # (B, T, 1)\n",
    "    logits = logits.squeeze() # (B, T)\n",
    "    logits = logits.view(1, -1) # (1, B*T)\n",
    "    prediction = self.lm_out(logits) # (1, 1)\n",
    "    prediction = prediction.view(1,) # (1,)\n",
    "    # print(\"i am in gpt\", prediction.device)\n",
    "    return prediction\n",
    "\n",
    "model = GPT()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0003)\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42340\n"
     ]
    }
   ],
   "source": [
    "num_training_steps = epochs * len(train_loader)\n",
    "\n",
    "print(num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate F1 score\n",
    "def evaluateF1Score(model, loader, device):\n",
    "    model.eval()\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    true_negatives = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            inputs = inputs.squeeze()\n",
    "            inputs = inputs[:, :window_size]\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            predicted = torch.round(torch.sigmoid(outputs))\n",
    "            \n",
    "            true_positives += ((predicted == 1) & (labels == 1)).sum().item()\n",
    "            false_positives += ((predicted == 1) & (labels == 0)).sum().item()\n",
    "            false_negatives += ((predicted == 0) & (labels == 1)).sum().item()\n",
    "            true_negatives += ((predicted == 0) & (labels == 0)).sum().item()\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives + 1e-15)\n",
    "    recall = true_positives / (true_positives + false_negatives + 1e-15)\n",
    "    \n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-15)\n",
    "\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, data_loader, loss_fn, eval_batch):\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss = 0.0\n",
    "    correct_eval = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader:\n",
    "            file = x.to(device)\n",
    "            file = file.squeeze()\n",
    "            file = file[:, :window_size]\n",
    "            label = y.to(device)\n",
    "\n",
    "            output = model(file)\n",
    "\n",
    "            if eval_batch == 1:\n",
    "                loss = loss_fn(output, label)\n",
    "            else:\n",
    "                loss = loss_fn(output, label.view(-1, 1))\n",
    "                \n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            preds = torch.where(output > 0.5, 1, 0).T\n",
    "            correct_eval += (preds == label).sum().item()\n",
    "\n",
    "        eval_loss = eval_loss / len(data_loader)\n",
    "        eval_acc = (correct_eval / (len(data_loader) * batch_size))\n",
    "        eval_f1 = evaluateF1Score(model, data_loader, device)\n",
    "\n",
    "    return eval_loss, eval_acc, eval_f1\n",
    "\n",
    "prev_eval_loss, prev_eval_acc, prev_eval_f1 = eval(model, val_loader, loss_fn, 1)\n",
    "print(\"Loss:\", round(prev_eval_loss, 3), \"Accuracy:\", round(prev_eval_acc, 3), \"F1 score:\", round(prev_eval_f1, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files to train on: 34\n",
      "Epoch: 0 \t Train loss: 3.22 \t Train acc: 0.41 \t Train F1: 0.00\n",
      "Epoch: 0 \t Val loss: 10.73 \t Val acc: 0.50 \t Val F1: 0.00\n",
      "=========================================\n",
      "Total files to train on: 34\n",
      "Epoch: 1 \t Train loss: 16.82 \t Train acc: 0.56 \t Train F1: 0.94\n",
      "Epoch: 1 \t Val loss: 38.90 \t Val acc: 0.50 \t Val F1: 0.67\n",
      "=========================================\n",
      "Total files to train on: 34\n",
      "Epoch: 2 \t Train loss: 22.01 \t Train acc: 0.65 \t Train F1: 0.00\n",
      "Epoch: 2 \t Val loss: 13.51 \t Val acc: 0.50 \t Val F1: 0.00\n",
      "=========================================\n",
      "Total files to train on: 34\n",
      "Epoch: 3 \t Train loss: 5.46 \t Train acc: 0.85 \t Train F1: 0.94\n",
      "Epoch: 3 \t Val loss: 21.75 \t Val acc: 0.50 \t Val F1: 0.67\n",
      "=========================================\n",
      "Total files to train on: 34\n",
      "Epoch: 4 \t Train loss: 2.70 \t Train acc: 0.88 \t Train F1: 0.94\n",
      "Epoch: 4 \t Val loss: 3.56 \t Val acc: 0.50 \t Val F1: 0.67\n",
      "=========================================\n",
      "Total files to train on: 34\n",
      "Epoch: 5 \t Train loss: 1.42 \t Train acc: 0.88 \t Train F1: 0.94\n",
      "Epoch: 5 \t Val loss: 2.55 \t Val acc: 0.50 \t Val F1: 0.67\n",
      "=========================================\n",
      "Total files to train on: 34\n",
      "Epoch: 6 \t Train loss: 0.18 \t Train acc: 0.97 \t Train F1: 1.00\n",
      "Epoch: 6 \t Val loss: 0.45 \t Val acc: 0.75 \t Val F1: 1.00\n",
      "=========================================\n",
      "WEIGHTS SAVED\n",
      "Total files to train on: 34\n",
      "Epoch: 7 \t Train loss: 0.02 \t Train acc: 1.00 \t Train F1: 1.00\n",
      "Epoch: 7 \t Val loss: 0.48 \t Val acc: 0.75 \t Val F1: 0.80\n",
      "=========================================\n",
      "Total files to train on: 34\n",
      "Epoch: 8 \t Train loss: 0.01 \t Train acc: 1.00 \t Train F1: 1.00\n",
      "Epoch: 8 \t Val loss: 0.50 \t Val acc: 0.50 \t Val F1: 0.67\n",
      "=========================================\n",
      "Total files to train on: 34\n",
      "Epoch: 9 \t Train loss: 0.01 \t Train acc: 1.00 \t Train F1: 1.00\n",
      "Epoch: 9 \t Val loss: 0.52 \t Val acc: 0.50 \t Val F1: 0.67\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "def train(model, data_loader, optimizer, loss_fn):\n",
    "  model.train()\n",
    "  train_loss = 0.0\n",
    "  correct_train = 0.0\n",
    "  optimizer.zero_grad()\n",
    "  for x,y in data_loader:\n",
    "        file = x.to(device)\n",
    "        file = file.squeeze()\n",
    "        file = file[:, :window_size]\n",
    "        label = y.to(device)\n",
    "        output = model(file)\n",
    "        with torch.no_grad():\n",
    "          preds = torch.where(output > 0.5, 1, 0).T\n",
    "          correct_train += ((preds == label)).sum().item()\n",
    "        # print(output.shape)\n",
    "        loss = loss_fn(output.view(-1, 1), label.view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "  train_loss = train_loss/len(data_loader)\n",
    "  train_acc = (correct_train/(len(data_loader)*batch_size))\n",
    "  train_f1 = evaluateF1Score(model, data_loader, device)\n",
    "  return train_loss, train_acc, train_f1\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    train_loss, train_acc, train_f1 = train(model, train_loader,optimizer, loss_fn)\n",
    "    print(f\"Epoch: {epoch} \\t Train loss: {train_loss:.2f} \\t Train acc: {train_acc:.2f} \\t Train F1: {train_f1:.2f}\")\n",
    "\n",
    "    eval_loss, eval_acc, val_f1 = eval(model, val_loader, loss_fn, eval_batch)\n",
    "    print(f\"Epoch: {epoch} \\t Val loss: {eval_loss:.2f} \\t Val acc: {eval_acc:.2f} \\t Val F1: {val_f1:.2f}\")\n",
    "\n",
    "    print(\"=========================================\")\n",
    "    if prev_eval_acc < eval_acc:\n",
    "      prev_eval_acc = eval_acc\n",
    "      torch.save(model.state_dict(), \"./trans.pt\")\n",
    "      print(\"WEIGHTS SAVED\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
